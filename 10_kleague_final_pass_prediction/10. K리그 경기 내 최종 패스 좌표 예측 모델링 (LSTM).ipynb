{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"toc_visible":true,"gpuType":"T4","mount_file_id":"18RrnWl2xRc2c3cbBZvAFl85MlECH-Ha6","authorship_tag":"ABX9TyOEoPm053M+UtJRIzE/FXUU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 1. Import"],"metadata":{"id":"Md7JpNQpLNhX"}},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","%cd \"/content/drive/MyDrive/데이터 분석/projects/ML_portfolio/10_kleague_final_pass_prediction\""],"metadata":{"id":"VV6_s3glLjVk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ghfBfk0p_TEn"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","import torch\n","from torch import nn\n","from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"markdown","source":["# 2. Hyperparameter Setting"],"metadata":{"id":"kNa67kkMLRG0"}},{"cell_type":"code","source":["TRAIN_PATH = \"Data/train.csv\"\n","BATCH_SIZE = 64\n","EPOCHS = 50\n","LR = 1e-3\n","HIDDEN_DIM = 96\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Using device:\", DEVICE)"],"metadata":{"id":"tMKajnMPLPJN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Data Load & Preprocessing"],"metadata":{"id":"AUBTtyfwLZ4z"}},{"cell_type":"code","source":["# event 단순화 매핑 함수\n","def simplify_event(t: str) -> str:\n","    if t in [\"Pass\", \"Pass_Freekick\", \"Pass_Corner\"]:\n","        return \"Pass\"\n","    if t == \"Carry\":\n","        return \"Carry\"\n","    if t in [\"Duel\", \"Tackle\", \"Interception\", \"Recovery\"]:\n","        return \"Duel_Turnover\"\n","    if t == \"Cross\":\n","        return \"Cross\"\n","    if t.startswith(\"Shot\"):\n","        return \"Shot\"\n","    if t == \"Penalty Kick\":\n","        return \"Shot\"\n","    if t in [\"Clearance\", \"Aerial Clearance\"]:\n","        return \"Clearance\"\n","    if t in [\"Catch\", \"Parry\", \"Goal Kick\", \"Keeper Rush-Out\"]:\n","        return \"GK_Action\"\n","    if t in [\"Block\", \"Deflection\", \"Intervention\", \"Hit\"]:\n","        return \"Deflect_Block\"\n","    if t == \"Throw-In\":\n","        return \"SetPiece\"\n","    if t in [\"Goal\", \"Own Goal\"]:\n","        return \"Goal_Event\"\n","    if t in [\"Error\", \"Out\", \"Foul\", \"Foul_Throw\", \"Handball_Foul\", \"Offside\"]:\n","        return \"Error_Out\"\n","    return \"Misc\"\n","\n","# 결과 단순화 함수\n","def simplify_result(result_name):\n","    if result_name in [\"Successful\", \"On Target\", \"Goal\"]:\n","        return \"Success\"\n","    if result_name in [\"Unsuccessful\", \"Off Target\", \"Blocked\"]:\n","        return \"Fail\"\n","    return \"None\"\n","\n","def build_episode_sequence(g: pd.DataFrame, for_train: bool = True):\n","    \"\"\"\n","    한 game_episode의 데이터프레임 g를 받아서\n","    - seq: [T, F] numeric feature 시퀀스\n","    - target: [2] (정규화된 end_x, end_y)\n","    을 반환하는 함수.\n","    \"\"\"\n","    g = g.reset_index(drop=True).copy()\n","    if len(g) < 2:\n","        return None, None, None, None\n","\n","    # 기본 좌표 & 시간\n","    sx = g[\"start_x\"].values\n","    sy = g[\"start_y\"].values\n","    t  = g[\"time_seconds\"].values\n","\n","    # 이동량\n","    dx = np.diff(sx, prepend=sx[0])\n","    dy = np.diff(sy, prepend=sy[0])\n","    dist = np.sqrt(dx**2 + dy**2)\n","    angle = np.arctan2(dy, dx)  # -pi ~ pi\n","\n","    # 시간차\n","    dt = np.diff(t, prepend=t[0])\n","    dt[dt < 0] = 0  # 역전 방지\n","\n","    # 누적 이동량\n","    cum_dx = np.cumsum(dx)\n","    cum_dy = np.cumsum(dy)\n","    move_norm = np.sqrt(cum_dx**2 + cum_dy**2)\n","\n","    # episode 내부 상대 위치\n","    T = len(g)\n","    step_idx = np.arange(T)\n","    step_idx_norm = step_idx / (T - 1) if T > 1 else np.zeros(T)\n","\n","    # 상대 시간 (0~1)\n","    t_min, t_max = t.min(), t.max()\n","    time_rel = (t - t_min) / (t_max - t_min) if t_max > t_min else np.zeros(T)\n","\n","    # -------------------------\n","    # 정규화 (EDA 기반 스케일링)\n","    # -------------------------\n","    sx_norm = sx / 105.0\n","    sy_norm = sy / 68.0\n","\n","    dx_norm = dx / 40.0\n","    dy_norm = dy / 40.0\n","    dist_norm = dist / 40.0\n","    angle_norm = angle / np.pi\n","\n","    # dt: 3초를 넘는 경우는 1로 클립\n","    dt_norm = np.clip(dt / 3.0, 0, 1)\n","\n","    cum_dx_norm = cum_dx / 60.0\n","    cum_dy_norm = cum_dy / 60.0\n","    move_norm_norm = move_norm / 60.0\n","\n","    # feature matrix 구성: [T, F]\n","    feats = np.stack([\n","        sx_norm, sy_norm,         # 2\n","        dx_norm, dy_norm,         # 2\n","        dist_norm,                # 1\n","        angle_norm,               # 1\n","        dt_norm,                  # 1\n","        cum_dx_norm, cum_dy_norm, # 2\n","        move_norm_norm,           # 1\n","        step_idx_norm,            # 1\n","        time_rel                  # 1\n","    ], axis=1).astype(\"float32\")  # 총 12차원\n","\n","    if \"event_s\" in g.columns:\n","        event_idx = g[\"event_s\"].apply(lambda x: event2idx[x]).values.astype(\"int64\")\n","    else:\n","        tmp_event = g[\"type_name\"].astype(str).apply(simplify_event)\n","        event_idx = tmp_event.apply(lambda x: event2idx[x]).values.astype(\"int64\")\n","\n","    if \"result_s\" in g.columns:\n","        result_idx = g[\"result_s\"].apply(lambda x: result2idx[x]).values.astype(\"int64\")\n","    else:\n","        tmp_result = g[\"result_name\"].astype(str).apply(simplify_result)\n","        result_idx = tmp_result.apply(lambda x: result2idx[x]).values.astype(\"int64\")\n","\n","    # target: 마지막 end_x, end_y\n","    target = None\n","\n","    if for_train:\n","        ex = g[\"end_x\"].values[-1] / 105.0\n","        ey = g[\"end_y\"].values[-1] / 68.0\n","        target = np.array([ex, ey], dtype=\"float32\")\n","\n","    return feats, event_idx, result_idx, target"],"metadata":{"id":"nqtPDf7YLU3L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(TRAIN_PATH)\n","df = df.sort_values([\"game_episode\", \"time_seconds\"]).reset_index(drop=True)\n","\n","df[\"event_s\"] = df[\"type_name\"].astype(str).apply(simplify_event)\n","df[\"result_s\"] = df[\"result_name\"].astype(str).apply(simplify_result)\n","\n","event_vocab = sorted(df[\"event_s\"].unique())\n","event2idx = {ev: i for i, ev in enumerate(event_vocab)}\n","\n","result_vocab = sorted(df[\"result_s\"].unique())\n","result2idx = {rs: i for i, rs in enumerate(result_vocab)}\n","\n","print(\"Event vocabulary size:\", len(event2idx), event2idx)\n","print(\"Result vocabulary size:\", len(result2idx), result2idx)"],"metadata":{"id":"LV90W8Sf6kua"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","Event vocabulary size: 11 {'Carry': 0, 'Clearance': 1, 'Cross': 2, 'Deflect_Block': 3, 'Duel_Turnover': 4, 'Error_Out': 5, 'GK_Action': 6, 'Misc': 7, 'Pass': 8, 'SetPiece': 9, 'Shot': 10}\n","Result vocabulary size: 3 {'Fail': 0, 'None': 1, 'Success': 2}\n","```\n","\n"],"metadata":{"id":"dwFEkn7Cx2Ra"}},{"cell_type":"code","source":["episodes, events, results, targets = [], [], [], []\n","\n","for _, g in tqdm(df.groupby(\"game_episode\")):\n","    seq, ev, rs, tgt = build_episode_sequence(g)\n","    if seq is None:\n","        continue\n","    episodes.append(seq)\n","    events.append(ev)\n","    results.append(rs)\n","    targets.append(tgt)\n","\n","print(\"Episode count:\", len(episodes))\n","print(\"Example episode shape:\", episodes[0].shape)\n","print(\"Example event len:\", len(events[0]), \"result len:\", len(results[0]))"],"metadata":{"id":"3kJjn9iK6PFi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","100%|██████████| 15435/15435 [00:13<00:00, 1107.46it/s]\n","\n","Episode count: 15428\n","Example episode shape: (49, 12)\n","Example event len: 49 result len: 49\n","```\n","\n"],"metadata":{"id":"Dr3m0dj9cm3M"}},{"cell_type":"markdown","source":["# 4. Custom Dataset / DataLoader 정의 및 Validation 분할"],"metadata":{"id":"RhLSjdqvL0tb"}},{"cell_type":"code","source":["class EpisodeDataset(torch.utils.data.Dataset):\n","    def __init__(self, seqs, evs, rss, tgts):\n","        self.seqs = seqs\n","        self.evs = evs\n","        self.rss = rss\n","        self.tgts = tgts\n","\n","    def __len__(self):\n","        return len(self.seqs)\n","\n","    def __getitem__(self, idx):\n","        seq = torch.tensor(self.seqs[idx])        # [T, 12]\n","        ev  = torch.tensor(self.evs[idx])         # [T]\n","        rs  = torch.tensor(self.rss[idx])         # [T]\n","        tgt = torch.tensor(self.tgts[idx])        # [2]\n","        return seq, ev, rs, seq.size(0), tgt\n","\n","def collate_fn(batch):\n","    seqs, evs, rss, lengths, tgts = zip(*batch)\n","\n","    lengths = torch.tensor(lengths)\n","    tgts    = torch.stack(tgts)\n","\n","    seqs_p = pad_sequence(seqs, batch_first=True)\n","    evs_p  = pad_sequence(evs, batch_first=True, padding_value=0)\n","    rss_p  = pad_sequence(rss, batch_first=True, padding_value=0)\n","\n","    return seqs_p, evs_p, rss_p, lengths, tgts\n","\n","idx_train, idx_valid = train_test_split(\n","    np.arange(len(episodes)), test_size=0.2, random_state=42\n",")\n","\n","train_loader = DataLoader(\n","    EpisodeDataset(\n","        [episodes[i] for i in idx_train],\n","        [events[i]   for i in idx_train],\n","        [results[i]  for i in idx_train],\n","        [targets[i]  for i in idx_train],\n","    ),\n","    batch_size=64, shuffle=True, collate_fn=collate_fn\n",")\n","\n","valid_loader = DataLoader(\n","    EpisodeDataset(\n","        [episodes[i] for i in idx_valid],\n","        [events[i]   for i in idx_valid],\n","        [results[i]  for i in idx_valid],\n","        [targets[i]  for i in idx_valid],\n","    ),\n","    batch_size=64, shuffle=False, collate_fn=collate_fn\n",")\n","\n","print(\"train episodes:\", len(idx_train), \"valid episodes:\", len(idx_valid))"],"metadata":{"id":"BJeZH7DALgcx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","train episodes: 12342 valid episodes: 3086\n","```\n","\n"],"metadata":{"id":"rNDeZMGBckaW"}},{"cell_type":"markdown","source":["# 5. LSTM 베이스라인 + 이동량 모델 정의"],"metadata":{"id":"p2z7Qk4UL4or"}},{"cell_type":"code","source":["class FinalPassLSTMWithLastK(nn.Module):\n","    def __init__(\n","        self,\n","        num_feats=12,\n","        event_emb_dim=6,\n","        result_emb_dim=3,\n","        hidden_dim=96,\n","        k_last=3,\n","        num_layers=1,\n","    ):\n","        super().__init__()\n","\n","        self.event_emb = nn.Embedding(len(event2idx), event_emb_dim)\n","        self.result_emb = nn.Embedding(len(result2idx), result_emb_dim)\n","\n","        input_dim = num_feats + event_emb_dim + result_emb_dim\n","\n","        self.lstm = nn.LSTM(\n","            input_size=input_dim,\n","            hidden_size=hidden_dim,\n","            num_layers=num_layers,\n","            batch_first=True,\n","        )\n","\n","        self.k_last = k_last\n","        self.lastk_mlp = nn.Sequential(\n","            nn.Linear(hidden_dim * k_last, hidden_dim),\n","            nn.ReLU(),\n","        )\n","\n","        self.fc = nn.Linear(hidden_dim * 2, 2)\n","\n","    def forward(self, seq, ev, rs, lengths):\n","\n","        ev_e = self.event_emb(ev)\n","        rs_e = self.result_emb(rs)\n","        x = torch.cat([seq, ev_e, rs_e], dim=-1)   # [B, T, D]\n","\n","        packed = pack_padded_sequence(\n","            x, lengths.cpu(), batch_first=True, enforce_sorted=False\n","        )\n","        packed_out, (h_n, c_n) = self.lstm(packed)\n","        out_padded, _ = pad_packed_sequence(packed_out, batch_first=True)\n","\n","        h_context = h_n[-1]  # [B, H]\n","\n","        B, T, H = out_padded.size()\n","        lastk_list = []\n","\n","        for i in range(B):\n","            L = lengths[i].item()\n","            end = L\n","            start = max(0, end - self.k_last)\n","            lastk = out_padded[i, start:end]\n","\n","            if lastk.size(0) < self.k_last:\n","                pad = torch.zeros(\n","                    self.k_last - lastk.size(0),\n","                    H,\n","                    device=seq.device,\n","                )\n","                lastk = torch.cat([pad, lastk], dim=0)\n","\n","            lastk_list.append(lastk.reshape(-1))\n","\n","        lastk_tensor = torch.stack(lastk_list)\n","\n","        h_lastk = self.lastk_mlp(lastk_tensor)\n","\n","        h = torch.cat([h_context, h_lastk], dim=1)\n","        out = self.fc(h)\n","\n","        return out"],"metadata":{"id":"nookOJsHL3LW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 6. 모델 학습 및 검증"],"metadata":{"id":"P4f3f-4rL9Lx"}},{"cell_type":"code","source":["model = FinalPassLSTMWithLastK().to(DEVICE)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.MSELoss()\n","\n","best_dist = float(\"inf\")\n","best_state = None\n","\n","for epoch in range(1, EPOCHS + 1):\n","    # --- Train ---\n","    model.train()\n","    total_loss = 0\n","\n","    for seq, ev, rs, lengths, tgt in train_loader:\n","        seq, ev, rs, lengths, tgt = (\n","            seq.to(DEVICE), ev.to(DEVICE), rs.to(DEVICE),\n","            lengths.to(DEVICE), tgt.to(DEVICE)\n","        )\n","\n","        optimizer.zero_grad()\n","        pred = model(seq, ev, rs, lengths)\n","        loss = criterion(pred, tgt)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item() * seq.size(0)\n","\n","    train_loss = total_loss / len(train_loader.dataset)\n","\n","    # --- Valid: 평균 유클리드 거리 ---\n","    model.eval()\n","    dists = []\n","\n","    with torch.no_grad():\n","        for seq, ev, rs, lengths, tgt in valid_loader:\n","            seq, ev, rs, lengths, tgt = (\n","                seq.to(DEVICE), ev.to(DEVICE), rs.to(DEVICE),\n","                lengths.to(DEVICE), tgt.to(DEVICE)\n","            )\n","\n","            pred = model(seq, ev, rs, lengths)\n","\n","            pred_np = pred.cpu().numpy()\n","            tgt_np = tgt.cpu().numpy()\n","\n","            px = pred_np[:, 0] * 105\n","            py = pred_np[:, 1] * 68\n","            tx = tgt_np[:, 0] * 105\n","            ty = tgt_np[:, 1] * 68\n","\n","            dist = np.sqrt((px - tx)**2 + (py - ty)**2)\n","            dists.append(dist)\n","\n","    mean_dist = np.concatenate(dists).mean()\n","\n","    print(f\"[Epoch {epoch}] train_loss={train_loss:.4f} | valid_mean_dist={mean_dist:.4f}\")\n","\n","    if mean_dist < best_dist:\n","        best_dist = mean_dist\n","        best_state = model.state_dict()\n","        print(f\"--> Best updated: {best_dist:.4f}\")"],"metadata":{"id":"DFVil3J5L6vC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","# baseline\n","[Epoch 18] train_loss=0.0304 | valid_mean_dist=16.6270\n"," --> Best model updated! (dist=16.6270)\n","\n","# hidden_dim=96으로 수정 후\n","[Epoch 27] train_loss=0.0282 | valid_mean_dist=16.3134\n"," --> Best model updated! (dist=16.3134)\n","\n","# hidden_dim=96으로 수정 + 컬럼 스케일링 범위 조정\n","[Epoch 28] train_loss=0.0287 | valid_mean_dist=16.2878\n"," --> Best model updated! (dist=16.2878)\n","\n","# Event Embedding 추가한 후\n","[Epoch 30] train_loss=0.0267 | valid_mean_dist=15.8609\n"," --> Best model updated! (dist=15.8609)\n","\n","# Result Embedding 추가한 후\n","[Epoch 26] train_loss=0.0262 | valid_mean_dist=15.6801\n","--> Best updated: 15.6801\n","\n","# Last-k Event 추가한 후\n","[Epoch 19] train_loss=0.0263 | valid_mean_dist=15.6266\n","--> Best updated: 15.6266\n","```\n","\n"],"metadata":{"id":"_3Z2XL0_de-y"}},{"cell_type":"markdown","source":["# 7. 평가 데이터셋 추론"],"metadata":{"id":"lsUazbcbMZ_a"}},{"cell_type":"code","source":["# ---------------------------------------------------------\n","# 0. 준비: 모델 로드\n","# ---------------------------------------------------------\n","model.load_state_dict(best_state)\n","model.eval()\n","\n","# ---------------------------------------------------------\n","# 1. Test 메타 로드\n","# ---------------------------------------------------------\n","test_meta = pd.read_csv(\"Data/test.csv\")\n","submission = pd.read_csv(\"Data/sample_submission.csv\")\n","submission = submission.merge(test_meta, on=\"game_episode\", how=\"left\")\n","\n","# ---------------------------------------------------------\n","# 2. test 파일 전체 캐싱 — 속도 10~20배 빨라짐\n","# ---------------------------------------------------------\n","def load_all_test_files(test_meta, base_dir=\"Data\"):\n","    cache = {}\n","    for path in tqdm(test_meta[\"path\"].unique(), desc=\"Loading test files\"):\n","        clean = path[1:]              # \"/XXX.csv\" → \"XXX.csv\"\n","        full_path = base_dir + clean\n","        df = pd.read_csv(full_path)\n","        cache[path] = df\n","    return cache\n","\n","file_cache = load_all_test_files(test_meta)\n","\n","# ---------------------------------------------------------\n","# 3. Inference\n","# ---------------------------------------------------------\n","preds_x, preds_y = [], []\n","\n","with torch.no_grad():\n","    for _, row in tqdm(submission.iterrows(), total=len(submission), desc=\"Inference\"):\n","        g = file_cache[row[\"path\"]].copy()\n","\n","        # event/result 단순화 컬럼 생성\n","        g[\"event_s\"] = g[\"type_name\"].astype(str).apply(simplify_event)\n","        g[\"result_s\"] = g[\"result_name\"].astype(str).apply(simplify_result)\n","\n","        seq, ev, rs, _ = build_episode_sequence(g, for_train=False)\n","\n","        seq = torch.tensor(seq).unsqueeze(0).to(DEVICE)\n","        ev  = torch.tensor(ev).unsqueeze(0).to(DEVICE)\n","        rs  = torch.tensor(rs).unsqueeze(0).to(DEVICE)\n","        L   = torch.tensor([seq.shape[1]]).to(DEVICE)\n","\n","        pred = model(seq, ev, rs, L)[0].cpu().numpy()\n","\n","        preds_x.append(pred[0] * 105)\n","        preds_y.append(pred[1] * 68)"],"metadata":{"id":"c7Kr_PH6MAGc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","Loading test files: 100%|██████████| 2414/2414 [08:54<00:00,  4.51it/s]\n","Inference: 100%|██████████| 2414/2414 [00:05<00:00, 470.82it/s]\n","```\n","\n"],"metadata":{"id":"4lyHowTYBK0B"}},{"cell_type":"markdown","source":["# 8. 제출 Submission 생성"],"metadata":{"id":"MIMzakLGMbf7"}},{"cell_type":"code","source":["submission[\"end_x\"] = preds_x\n","submission[\"end_y\"] = preds_y\n","submission[[\"game_episode\", \"end_x\", \"end_y\"]].to_csv(\"Data/step4_submit.csv\", index=False)\n","\n","print(\"Saved: Data/step4_submit.csv\")"],"metadata":{"id":"c3_ULFUNMdYE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aq9ImZGI2ut6"},"execution_count":null,"outputs":[]}]}