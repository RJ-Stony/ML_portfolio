{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"toc_visible":true,"gpuType":"T4","mount_file_id":"18RrnWl2xRc2c3cbBZvAFl85MlECH-Ha6","authorship_tag":"ABX9TyMf1yFpqR2b7EYqqXA7nu4u"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 1. Import"],"metadata":{"id":"Md7JpNQpLNhX"}},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","%cd \"/content/drive/MyDrive/데이터 분석/projects/ML_portfolio/10_kleague_final_pass_prediction\""],"metadata":{"id":"VV6_s3glLjVk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ghfBfk0p_TEn"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","import torch\n","from torch import nn\n","from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"markdown","source":["# 2. Hyperparameter Setting"],"metadata":{"id":"kNa67kkMLRG0"}},{"cell_type":"code","source":["TRAIN_PATH = \"Data/train.csv\"\n","BATCH_SIZE = 64\n","EPOCHS = 30\n","LR = 1e-3\n","HIDDEN_DIM = 96\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Using device:\", DEVICE)"],"metadata":{"id":"tMKajnMPLPJN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Data Load & Preprocessing"],"metadata":{"id":"AUBTtyfwLZ4z"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","df = pd.read_csv(TRAIN_PATH)\n","df = df.sort_values([\"game_episode\", \"time_seconds\"]).reset_index(drop=True)\n","\n","def build_episode_sequence(g: pd.DataFrame, for_train: bool = True):\n","    \"\"\"\n","    한 game_episode의 데이터프레임 g를 받아서\n","    - seq: [T, F] numeric feature 시퀀스\n","    - target: [2] (정규화된 end_x, end_y)\n","    을 반환하는 함수.\n","    \"\"\"\n","    g = g.reset_index(drop=True).copy()\n","    if len(g) < 2:\n","        return None, None\n","\n","    # 기본 좌표 & 시간\n","    sx = g[\"start_x\"].values\n","    sy = g[\"start_y\"].values\n","    t  = g[\"time_seconds\"].values\n","\n","    # 이동량\n","    dx = np.diff(sx, prepend=sx[0])\n","    dy = np.diff(sy, prepend=sy[0])\n","    dist = np.sqrt(dx**2 + dy**2)\n","    angle = np.arctan2(dy, dx)  # -pi ~ pi\n","\n","    # 시간차\n","    dt = np.diff(t, prepend=t[0])\n","    dt[dt < 0] = 0  # 역전 방지\n","\n","    # 누적 이동량\n","    cum_dx = np.cumsum(dx)\n","    cum_dy = np.cumsum(dy)\n","    move_norm = np.sqrt(cum_dx**2 + cum_dy**2)\n","\n","    # episode 내부 상대 위치\n","    T = len(g)\n","    step_idx = np.arange(T)\n","    step_idx_norm = step_idx / (T - 1) if T > 1 else np.zeros(T)\n","\n","    # 상대 시간 (0~1)\n","    t_min, t_max = t.min(), t.max()\n","    time_rel = (t - t_min) / (t_max - t_min) if t_max > t_min else np.zeros(T)\n","\n","    # -------------------------\n","    # 정규화 (EDA 기반 스케일링)\n","    # -------------------------\n","    sx_norm = sx / 105.0\n","    sy_norm = sy / 68.0\n","\n","    dx_norm = dx / 40.0\n","    dy_norm = dy / 40.0\n","    dist_norm = dist / 40.0\n","    angle_norm = angle / np.pi\n","\n","    # dt: 3초를 넘는 경우는 1로 클립\n","    dt_norm = np.clip(dt / 3.0, 0, 1)\n","\n","    cum_dx_norm = cum_dx / 60.0\n","    cum_dy_norm = cum_dy / 60.0\n","    move_norm_norm = move_norm / 60.0\n","\n","    # feature matrix 구성: [T, F]\n","    feats = np.stack([\n","        sx_norm, sy_norm,         # 2\n","        dx_norm, dy_norm,         # 2\n","        dist_norm,                # 1\n","        angle_norm,               # 1\n","        dt_norm,                  # 1\n","        cum_dx_norm, cum_dy_norm, # 2\n","        move_norm_norm,           # 1\n","        step_idx_norm,            # 1\n","        time_rel                  # 1\n","    ], axis=1).astype(\"float32\")  # 총 12차원\n","\n","    # target: 마지막 end_x, end_y\n","    target = None\n","    if for_train:\n","        ex = g[\"end_x\"].values[-1] / 105.0\n","        ey = g[\"end_y\"].values[-1] / 68.0\n","        target = np.array([ex, ey], dtype=\"float32\")\n","\n","    return feats, target\n","\n","episodes = []\n","targets = []\n","\n","for _, g in tqdm(df.groupby(\"game_episode\")):\n","    seq, tgt = build_episode_sequence(g, for_train=True)\n","    if seq is None:\n","        continue\n","    episodes.append(seq)\n","    targets.append(tgt)\n","\n","print(\"에피소드 수:\", len(episodes))\n","print(\"예시 seq shape:\", episodes[0].shape)"],"metadata":{"id":"nqtPDf7YLU3L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","100%|██████████| 15435/15435 [00:07<00:00, 2065.18it/s]\n","\n","에피소드 수: 15428\n","예시 seq shape: (49, 12)\n","```\n","\n"],"metadata":{"id":"Dr3m0dj9cm3M"}},{"cell_type":"markdown","source":["# 4. Custom Dataset / DataLoader 정의 및 Validation 분할"],"metadata":{"id":"RhLSjdqvL0tb"}},{"cell_type":"code","source":["class EpisodeDataset(Dataset):\n","    def __init__(self, episodes, targets):\n","        self.episodes = episodes\n","        self.targets = targets\n","\n","    def __len__(self):\n","        return len(self.episodes)\n","\n","    def __getitem__(self, idx):\n","        seq = torch.tensor(self.episodes[idx])   # [T, 12]\n","        tgt = torch.tensor(self.targets[idx])    # [2]\n","        length = seq.size(0)\n","        return seq, length, tgt\n","\n","def collate_fn(batch):\n","    seqs, lengths, tgts = zip(*batch)\n","    lengths = torch.tensor(lengths, dtype=torch.long)\n","    padded = pad_sequence(seqs, batch_first=True)  # [B, T, 12]\n","    tgts = torch.stack(tgts, dim=0)                # [B, 2]\n","    return padded, lengths, tgts\n","\n","# 에피소드 단위 train / valid split\n","idx_train, idx_valid = train_test_split(\n","    np.arange(len(episodes)), test_size=0.2, random_state=42\n",")\n","\n","episodes_train = [episodes[i] for i in idx_train]\n","targets_train  = [targets[i]  for i in idx_train]\n","episodes_valid = [episodes[i] for i in idx_valid]\n","targets_valid  = [targets[i]  for i in idx_valid]\n","\n","train_loader = DataLoader(\n","    EpisodeDataset(episodes_train, targets_train),\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    collate_fn=collate_fn,\n",")\n","\n","valid_loader = DataLoader(\n","    EpisodeDataset(episodes_valid, targets_valid),\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    collate_fn=collate_fn,\n",")\n","\n","print(\"train episodes:\", len(episodes_train), \"valid episodes:\", len(episodes_valid))"],"metadata":{"id":"BJeZH7DALgcx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","train episodes: 12342 valid episodes: 3086\n","```\n","\n"],"metadata":{"id":"rNDeZMGBckaW"}},{"cell_type":"markdown","source":["# 5. LSTM 베이스라인 + 이동량 모델 정의"],"metadata":{"id":"p2z7Qk4UL4or"}},{"cell_type":"code","source":["NUM_FEATS = episodes[0].shape[1]  # 12\n","\n","class LSTMBaseline(nn.Module):\n","    def __init__(self, input_dim=NUM_FEATS, hidden_dim=64):\n","        super().__init__()\n","        self.lstm = nn.LSTM(\n","            input_size=input_dim,\n","            hidden_size=hidden_dim,\n","            num_layers=1,\n","            batch_first=True,\n","        )\n","        self.fc = nn.Linear(hidden_dim, 2)  # (x_norm, y_norm)\n","\n","    def forward(self, x, lengths):\n","        # x: [B, T, F], lengths: [B]\n","        packed = pack_padded_sequence(\n","            x, lengths.cpu(), batch_first=True, enforce_sorted=False\n","        )\n","        _, (h_n, _) = self.lstm(packed)\n","        h_last = h_n[-1]      # [B, H] 마지막 layer의 hidden state\n","        out = self.fc(h_last) # [B, 2]\n","        return out\n","\n","model = LSTMBaseline(input_dim=NUM_FEATS, hidden_dim=HIDDEN_DIM).to(DEVICE)\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=LR)"],"metadata":{"id":"nookOJsHL3LW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 6. 모델 학습 및 검증"],"metadata":{"id":"P4f3f-4rL9Lx"}},{"cell_type":"code","source":["best_dist = float(\"inf\")\n","best_model_state = None\n","\n","for epoch in range(1, EPOCHS + 1):\n","    # --- Train ---\n","    model.train()\n","    total_loss = 0.0\n","\n","    for X, lengths, y in tqdm(train_loader):\n","        X, lengths, y = X.to(DEVICE), lengths.to(DEVICE), y.to(DEVICE)\n","\n","        optimizer.zero_grad()\n","        pred = model(X, lengths)\n","        loss = criterion(pred, y)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item() * X.size(0)\n","\n","    train_loss = total_loss / len(train_loader.dataset)\n","\n","    # --- Valid: 평균 유클리드 거리 ---\n","    model.eval()\n","    dists = []\n","\n","    with torch.no_grad():\n","        for X, lengths, y in tqdm(valid_loader):\n","            X, lengths, y = X.to(DEVICE), lengths.to(DEVICE), y.to(DEVICE)\n","            pred = model(X, lengths)\n","\n","            pred_np = pred.cpu().numpy()\n","            true_np = y.cpu().numpy()\n","\n","            pred_x = pred_np[:, 0] * 105.0\n","            pred_y = pred_np[:, 1] * 68.0\n","            true_x = true_np[:, 0] * 105.0\n","            true_y = true_np[:, 1] * 68.0\n","\n","            dist = np.sqrt((pred_x - true_x) ** 2 + (pred_y - true_y) ** 2)\n","            dists.append(dist)\n","\n","    mean_dist = np.concatenate(dists).mean()\n","\n","    print(\n","        f\"[Epoch {epoch}] \"\n","        f\"train_loss={train_loss:.4f} | \"\n","        f\"valid_mean_dist={mean_dist:.4f}\"\n","    )\n","\n","    if mean_dist < best_dist:\n","        best_dist = mean_dist\n","        best_model_state = model.state_dict().copy()\n","        print(f\" --> Best model updated! (dist={best_dist:.4f})\")"],"metadata":{"id":"DFVil3J5L6vC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","# baseline\n","[Epoch 18] train_loss=0.0304 | valid_mean_dist=16.6270\n"," --> Best model updated! (dist=16.6270)\n","\n","# hidden_dim=96으로 수정 후\n"," [Epoch 27] train_loss=0.0282 | valid_mean_dist=16.3134\n"," --> Best model updated! (dist=16.3134)\n","\n","# hidden_dim=96으로 수정 + 컬럼 스케일링 범위 조정\n"," [Epoch 28] train_loss=0.0287 | valid_mean_dist=16.2878\n"," --> Best model updated! (dist=16.2878)\n","```\n","\n"],"metadata":{"id":"_3Z2XL0_de-y"}},{"cell_type":"markdown","source":["# 7. 평가 데이터셋 추론"],"metadata":{"id":"lsUazbcbMZ_a"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import torch\n","from tqdm import tqdm\n","\n","# ---------------------------------------------------------\n","# 1) Test 파일 전체를 메모리에 미리 적재 (속도 핵심)\n","# ---------------------------------------------------------\n","def load_all_test_files(test_meta, base_dir=\"Data\"):\n","    cache = {}\n","    for path in tqdm(test_meta[\"path\"].unique(), desc=\"Loading test files\"):\n","        # path가 '/파일명.csv' 형태라서 앞 슬래시 제거\n","        clean = path[1:]\n","        full_path = base_dir + clean\n","        df = pd.read_csv(full_path)\n","        cache[path] = df\n","    return cache\n","\n","\n","# ---------------------------------------------------------\n","# 2) Inference\n","# ---------------------------------------------------------\n","model.load_state_dict(best_model_state)\n","model.eval()\n","\n","test_meta = pd.read_csv(\"Data/test.csv\")\n","submission = pd.read_csv(\"Data/sample_submission.csv\")\n","submission = submission.merge(test_meta, on=\"game_episode\", how=\"left\")\n","\n","# 파일 캐싱\n","file_cache = load_all_test_files(test_meta)\n","\n","preds_x, preds_y = [], []\n","\n","with torch.no_grad():\n","    for _, row in tqdm(submission.iterrows(), total=len(submission), desc=\"Inference\"):\n","        g = file_cache[row[\"path\"]]    # 캐시에서 즉시 가져오기 (매우 빠름)\n","\n","        seq, _ = build_episode_sequence(g, for_train=False)\n","\n","        # 방어 코드: seq가 None일 경우 fallback\n","        if seq is None:\n","            sx = g[\"start_x\"].values[-1] / 105.0\n","            sy = g[\"start_y\"].values[-1] / 68.0\n","            pred_norm = np.array([sx, sy], dtype=\"float32\")\n","        else:\n","            x = torch.tensor(seq, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n","            length = torch.tensor([seq.shape[0]]).to(DEVICE)\n","\n","            pred = model(x, length)[0].cpu().numpy()\n","            pred_norm = pred\n","\n","        preds_x.append(pred_norm[0] * 105.0)\n","        preds_y.append(pred_norm[1] * 68.0)"],"metadata":{"id":"c7Kr_PH6MAGc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 8. 제출 Submission 생성"],"metadata":{"id":"MIMzakLGMbf7"}},{"cell_type":"code","source":["submission[\"end_x\"] = preds_x\n","submission[\"end_y\"] = preds_y\n","submission[[\"game_episode\", \"end_x\", \"end_y\"]].to_csv(\n","    \"Data/baseline_step1_numeric_fe_fast.csv\",\n","    index=False,\n",")\n","\n","print(\"Saved: baseline_step1_numeric_fe_fast.csv\")"],"metadata":{"id":"c3_ULFUNMdYE"},"execution_count":null,"outputs":[]}]}