{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"toc_visible":true,"mount_file_id":"1RY0Fx5EBoe7SHdFMOWy05HSYgreAu28Q","authorship_tag":"ABX9TyONHgfbTFmlrB5t62Dh/0Jb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 0. 사전 세팅"],"metadata":{"id":"LrAsOz8GWlra"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LGieDGDXVh4D"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","%cd \"/content/drive/MyDrive/데이터 분석/projects/ML_portfolio/10_kleague_final_pass_prediction\""]},{"cell_type":"code","source":["!sudo apt-get install -y fonts-nanum\n","!sudo fc-cache -fv\n","!rm ~/.cache/matplotlib -rf"],"metadata":{"id":"--aOM1riNtXk","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 7. EDA 인사이트"],"metadata":{"id":"JsNdGhiOy9Px"}},{"cell_type":"markdown","source":["---\n","\n","▸ 타겟 구조\n","\n","    에피소드별 마지막 이벤트는 항상 Pass이고, 그 Pass의 (end_x, end_y)가 타겟\n","    패스 성공/실패 비율 ≈ 56:44 정도로 아주 심하게 치우치지 않음\n","    거리 기준으로 보면 10~20m 구간의 패스 성공률이 가장 높고, 30m 이상부터 급격히 떨어짐\n","\n","    < 인사이트 >\n","    - 순수 좌표 회귀(MAE/MSE) + 거리 관련 feature를 같이 쓰면 좋을 듯 !\n","    - multi-task로 distance_bin(0–10 / 10–20 / ...)이나 zone까지 같이 예측하게 하면 representation quality가 좋아질 수 있음\n","\n","▸ 시퀀스/정렬 구조\n","\n","    전체 에피소드 중 98% 이상은 시간 순서 정렬이 깔끔하고, 나머지 1.8% 정도만 역전이 있음\n","    대부분 -0.1 이내의 미세 오차, 진짜 심각한 역전은 적음\n","\n","    < 인사이트 >\n","    - 시퀀스 모델은 써도 될 것 같고 !\n","    - 단, 전처리에서 time_seconds, action_id 기준으로 확실하게 정렬하고, 마스크 처리만 잘 해주면 됨\n","    - 몇 개 안 되는 진짜 이상치는 드롭하거나 별도 처리해도 전체 성능에 영향 거의 없음\n","\n","▸ 이벤트 구성 패턴\n","\n","    전체 이벤트 중 Pass ≈ 50%, Carry ≈ 23%, Turnover 관련(Recovery + Interception + Tackle + Duel) ≈ 15%\n","    최빈 bigram: Pass→Pass, Carry→Pass, Pass→Carry, Turnover→Pass\n","    최빈 trigram: Pass-Carry-Pass, Pass-Pass-Pass, Carry-Pass-Pass 등\n","\n","    < 인사이트 >\n","    - n-gram 구조가 강해서 TCN(1D conv), RNN, Transformer 모두 잘 맞는 도메인\n","    - 특히 Carry → Pass, Turnover → Pass 같은 패턴은 final pass 위치와 전술 의도를 암시해줄 수 있음\n","\n","▸ 마지막 이벤트 직전 패턴\n","\n","    Final pass 바로 직전 이벤트의 90%가 Carry / Pass / Recovery 셋 중 하나\n","    평균 end_x/거리 기준으로 보면 Carry / Tackle 직후 패스가 가장 전방, 가장 먼 거리\n","\n","    < 인사이트 >\n","    - prev_event_type, prev_event_dx/dy/angle는 무조건 써야하는 feature\n","    - 심지어 “마지막 3~4 스텝만 따로 뽑아서 쓰는 모델”도 하나의 strong baseline으로 가능할 듯\n","\n","▸ Episode별 클러스터 (5개 패턴)\n","\n","    Balanced build-up / 짧은 측면 전개 / 리셋/후퇴 패턴 / 짧은 반대 측면 전개 / 긴 빌드업 (dist_cum 가장 큼)\n","    마지막 패스 성공률까지 보면 Cluster 4 (Long Build-up)가 최상(~0.63)\n","\n","    < 인사이트 >\n","    - episode에 붙는 cluster_id 자체가 embedding으로 사용될 수 있음\n","    - Mixture-of-experts / cluster-wise head 같은 구조도 고려 가능\n","    - 최소한 cluster_id를 one-hot 또는 embedding으로 넣으면, “지금의 빌드업 흐름이 어떤 종류인지” 모델이 한 번에 인식\n","\n","▸ Player별 분석 결과\n","\n","    선수별 carry_ratio 분포가 그렇게 극단적이지 않음\n","    선수별 angle_mean, final pass (end_x, end_y) mean 위치도 좁은 범위에 몰려 있고, 뚜렷한 클러스터 구조 없음\n","\n","    < 인사이트 >\n","    - player_id embedding은 효과 대비 리스크(차원+노이즈) 가 큼\n","    - baseline에서는 아예 빼고 시작하는 게 합리적\n","    - 나중에 여유 있으면 작은 차원(8~16) + strong dropout으로 시험해보는 정도\n","\n","▸ Episode별 움직임 & 각도 smoothness\n","\n","    cum_dx, cum_dy로 episode가 전진 위주인지, 좌우 측면 전개인지가 드러남\n","    angle 변화량 기준으로 보면, 누적 전진량이 클수록 angle이 더 안정(episode가 한 방향으로 쭉 진행)\n","\n","    < 인사이트 >\n","    - cum_dx, cum_dy, movement_norm, angle_mean_abs, angle_std는 전술 패턴을 대표하는 episode별 feature\n","    - final pass의 zone/거리/각도 예측에 직접적인 신호를 줌\n","\n","▸ Turnover 이후 3-step window\n","\n","    Turnover 직후 첫 행동은 dx ~ 0 (잡아두기), 그 이후 2~3 step에서 전진/측면 전개가 본격적으로 나타남\n","\n","    < 인사이트 >\n","    - “turnover 이후 k-step” 여부를 표시하는 feature가 유용하게 쓰일 수 있음\n","    - 특히 final pass가 turnover 직후 짧은 시퀀스에서 나오는지, 긴 빌드업 끝에서 나오는지 구분해줄 수 있음"],"metadata":{"id":"T3sdgeqPzBv5"}},{"cell_type":"markdown","source":["# 8. EDA에 이은 Feature Engineering (함수 정의)"],"metadata":{"id":"U9v6nLtX4Kpq"}},{"cell_type":"markdown","source":["---\n","\n","▸ 패스 각도(angle)\n","\n","    angle = arctan((end_y-start_y) / (end_x-start_x))\n","\n","    풀백은 측면으로 많이 주고, 중앙 미드필더는 전진 패스의 비율 높음\n","    수비수는 옆으로 주는 패스나 후방 패스의 비중 높음\n","\n","▸ 패스 진행 거리\n","\n","    더 먼 패스일수록 progressive chance가 높고, end_x가 강하게 증가하는 패턴을 가짐\n","\n","▸ event_type 임베딩\n","\n","    type_name → embedding vector\n","    result_name → embedding vector\n","\n","    sequence embedding에 필수적으로 진행해야하는 것\n","\n","▸ 에피소드에서의 속도(Δx, Δy)\n","\n","    dx_t = x_t - x_(t-1)\n","    dy_t = y_t - y_(t-1)\n","\n","    엔드 투 엔드 모델보다 훨씬 패턴 학습이 잘 됨\n","\n","    dx > 0 → 오른쪽으로 전진 중\n","    dy > 0 → 위쪽으로 이동 중\n","    dy < 0 → 아래쪽으로 이동 중\n","    dx ≈ 0 → 횡패스 빈도 높음\n","    dx < 0 → 후방 패스 비율 증가 (안정화)\n","\n","    1. 한 에피소드에서 dx가 계속 증가한다 ➜ 공격 전개 중 (전진 패스 가능성이 높음)\n","    2. dy가 크게 증가했다➜ 측면 전개 중 (사이드로 패스가 날아갈 가능성)\n","    3. dx가 음수로 전환되었다 ➜ 후방 안정화 패스 패턴\n","    4. dx, dy가 급격히 바뀐다 ➜ 압박을 벗어나기 위한 빠른 전개"],"metadata":{"id":"-ZPcy6vA4OFP"}},{"cell_type":"markdown","source":["## 8.1 공통 Util & 기본 데이터 정렬"],"metadata":{"id":"HvP_0jkzmws9"}},{"cell_type":"markdown","source":["### 8.1.1 이벤트 단순화(클러스터링), Zone 함수 (EDA에서 쓰던 것 정리)"],"metadata":{"id":"zS22enxvm3PT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OfpfRXNllmfT"},"outputs":[],"source":["from collections import Counter\n","from math import log2\n","\n","# 이벤트 타입 단순화하는 함수\n","def simplify_event(t: str) -> str:\n","    # Pass 계열\n","    if t in [\"Pass\", \"Pass_Freekick\", \"Pass_Corner\"]:\n","        return \"Pass\"\n","\n","    # Carry\n","    if t == \"Carry\":\n","        return \"Carry\"\n","\n","    # Duel / Turnover 계열\n","    if t in [\"Duel\", \"Tackle\", \"Interception\", \"Recovery\"]:\n","        return \"Duel_Turnover\"\n","\n","    # Cross (정확히 Cross만)\n","    if t == \"Cross\":\n","        return \"Cross\"\n","\n","    # Shot 계열\n","    if t.startswith(\"Shot\"):\n","        return \"Shot\"\n","\n","    # Penalty Kick은 Shot 계열로 통합\n","    if t == \"Penalty Kick\":\n","        return \"Shot\"\n","\n","    # Clearance\n","    if t in [\"Clearance\", \"Aerial Clearance\"]:\n","        return \"Clearance\"\n","\n","    # GK Action\n","    if t in [\"Catch\", \"Parry\", \"Goal Kick\", \"Keeper Rush-Out\"]:\n","        return \"GK_Action\"\n","\n","    # Block / Deflection / Intervention / Hit\n","    if t in [\"Block\", \"Deflection\", \"Intervention\", \"Hit\"]:\n","        return \"Deflect_Block\"\n","\n","    # Set-piece\n","    if t == \"Throw-In\":\n","        return \"SetPiece\"\n","\n","    # Goal 이벤트\n","    if t in [\"Goal\", \"Own Goal\"]:\n","        return \"Goal_Event\"\n","\n","    # Error 계열\n","    if t in [\"Error\", \"Out\", \"Foul\", \"Foul_Throw\", \"Handball_Foul\", \"Offside\"]:\n","        return \"Error_Out\"\n","\n","    return \"Misc\"\n","\n","# 이벤트 결과 단순화하는 함수\n","def simplify_result(result_name):\n","    if result_name in [\"Successful\", \"On Target\", \"Goal\"]:\n","        return \"Success\"\n","\n","    if result_name in [\"Unsuccessful\", \"Off Target\", \"Blocked\"]:\n","        return \"Fail\"\n","\n","    return \"None\"\n","\n","# Zone 구분하는 함수\n","def get_zone_x(x):\n","    if x < 35: return \"D3\"\n","    elif x < 70: return \"M3\"\n","    else: return \"A3\"\n","\n","def get_zone_y(y):\n","    if y < 22: return \"Left\"\n","    elif y < 45: return \"Center\"\n","    else: return \"Right\"\n","\n","# 시퀀스(에피소드) 엔트로피 측정하는 함수\n","def sequence_entropy(seq):\n","    cnt = Counter(seq)\n","    total = len(seq)\n","\n","    if total == 0:\n","        return 0.0\n","\n","    probs = [c / total for c in cnt.values()]\n","\n","    return -sum(p * log2(p) for p in probs if p > 0)"]},{"cell_type":"markdown","source":["### 8.1.2 기본 정렬 함수\n","\n","---\n","\n","    정렬이 이미 되어있는 데이터라 재정렬시키면 깨질 수 있음 - 삭제"],"metadata":{"id":"CnydgHlEqMkD"}},{"cell_type":"code","source":["# SORT_COLS = [\"game_episode\", \"time_seconds\", \"action_id\"]\n","\n","# def sort_events(df: pd.DataFrame) -> pd.DataFrame:\n","#     \"\"\"\n","#     time_seconds, action_id 기준으로 episode 내 이벤트 정렬.\n","#     \"\"\"\n","#     df_sorted = df.sort_values(SORT_COLS).reset_index(drop=True)\n","#     return df_sorted"],"metadata":{"id":"ZPemOp1FolOF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 8.2 이벤트별 Feature Engineering"],"metadata":{"id":"E3IZ85NIqT1I"}},{"cell_type":"markdown","source":["---\n","\n","    한 이벤트마다 어떤 Feature를 만들지를 담당하는 함수"],"metadata":{"id":"RyzkRhA2qbrG"}},{"cell_type":"markdown","source":["### 8.2.1 Turnover flag 계산 (EDA에서 쓴 함수)"],"metadata":{"id":"O2nl_EnMu3Kf"}},{"cell_type":"code","source":["def add_turnover_flag(df):\n","    df = df.copy()\n","\n","    # Fail 정의\n","    fail = df[\"result_simple\"] == \"Fail\"\n","\n","    # Pass / Cross / SetPiece 실패 → turnover\n","    cond_fail_pass = df[\"event_simple\"].isin([\"Pass\", \"Cross\", \"SetPiece\"]) & fail\n","\n","    # Take-On 실패\n","    cond_takeon_fail = (df[\"type_name\"] == \"Take-On\") & (df[\"result_name\"] == \"Unsuccessful\")\n","\n","    # Duel 실패\n","    cond_duel_fail = (df[\"type_name\"] == \"Duel\") & (df[\"result_name\"] == \"Unsuccessful\")\n","\n","    # 상대가 소유권 획득하는 이벤트\n","    cond_gain = df[\"event_simple\"] == \"Duel_Turnover\"\n","\n","    # Dead ball turnover\n","    cond_deadball = df[\"event_simple\"] == \"Error_Out\"\n","\n","    df[\"is_turnover\"] = (\n","        cond_fail_pass |\n","        cond_takeon_fail |\n","        cond_duel_fail |\n","        cond_gain |\n","        cond_deadball\n","    ).astype(int)\n","\n","    return df"],"metadata":{"id":"fg2Te6kwqSvz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 8.2.2 episode 내 좌표 차이 / 시간 차이 등 계산 함수"],"metadata":{"id":"VEHnIAg6xCRW"}},{"cell_type":"code","source":["import numpy as np\n","\n","def add_movement_features(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    episode 내 start_x, start_y 기준으로 dx, dy, distance, angle, dt 등 추가.\n","    \"\"\"\n","    df = df.copy()\n","    # df = sort_events(df)\n","\n","    df[\"dx\"] = df.groupby(\"game_episode\")[\"start_x\"].diff().fillna(0)\n","    df[\"dy\"] = df.groupby(\"game_episode\")[\"start_y\"].diff().fillna(0)\n","\n","    df[\"distance\"] = np.sqrt(df[\"dx\"]**2 + df[\"dy\"]**2)\n","\n","    df[\"angle\"] = np.arctan2(df[\"dy\"], df[\"dx\"]).fillna(0)\n","\n","    # 시간차 안정화\n","    dt = df.groupby(\"game_episode\")[\"time_seconds\"].diff()\n","    dt = dt.fillna(0)\n","    dt[dt < 0] = 0\n","    df[\"dt\"] = dt\n","\n","    # step index\n","    df[\"step_idx\"] = df.groupby(\"game_episode\").cumcount()\n","    df[\"epi_len\"] = df.groupby(\"game_episode\")[\"step_idx\"].transform(\"max\") + 1\n","\n","    df[\"step_idx_norm\"] = df[\"step_idx\"] / df[\"epi_len\"].clip(lower=1)\n","\n","    # relative time\n","    t_min = df.groupby(\"game_episode\")[\"time_seconds\"].transform(\"min\")\n","    t_max = df.groupby(\"game_episode\")[\"time_seconds\"].transform(\"max\")\n","    df[\"time_rel\"] = (df[\"time_seconds\"] - t_min) / (t_max - t_min).replace(0, 1)\n","\n","    return df"],"metadata":{"id":"axknzD2vw2Ux"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 8.2.3 zone / 골 방향 feature 함수"],"metadata":{"id":"KpGk9YfxyBG2"}},{"cell_type":"code","source":["def add_categorical_features(df: pd.DataFrame) -> pd.DataFrame:\n","    df = df.copy()\n","\n","    # 단순화\n","    df[\"event_simple\"] = df[\"type_name\"].apply(simplify_event)\n","    df[\"result_simple\"] = df[\"result_name\"].apply(simplify_result)\n","\n","    # zone\n","    df[\"zone_x\"] = df[\"start_x\"].apply(get_zone_x)\n","    df[\"zone_y\"] = df[\"start_y\"].apply(get_zone_y)\n","\n","    # 골대 기준 거리/각도 (오른쪽 골대 기준)\n","    goal_x, goal_y = 105.0, 34.0\n","    df[\"dist_to_goal\"] = np.sqrt((goal_x - df[\"start_x\"])**2 +\n","                                 (goal_y - df[\"start_y\"])**2)\n","    goal_angle = np.arctan2(goal_y - df[\"start_y\"],\n","                            goal_x - df[\"start_x\"])\n","    df[\"angle_to_goal\"] = goal_angle\n","\n","    return df"],"metadata":{"id":"bx2dbhxsxM5U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 8.2.4 Episode 누적 이동량 계산 함수"],"metadata":{"id":"7yFTd4zZyMbs"}},{"cell_type":"code","source":["def add_episode_cumulative_movement(df: pd.DataFrame) -> pd.DataFrame:\n","    df = df.copy()\n","    # df = sort_events(df)\n","\n","    df[\"cum_dx\"] = df.groupby(\"game_episode\")[\"dx\"].cumsum()\n","    df[\"cum_dy\"] = df.groupby(\"game_episode\")[\"dy\"].cumsum()\n","    df[\"movement_norm\"] = np.sqrt(df[\"cum_dx\"]**2 + df[\"cum_dy\"]**2)\n","\n","    return df"],"metadata":{"id":"M0HvCTVSyHUK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 8.2.5 최종 적용 함수"],"metadata":{"id":"ZIH77OvoyR3T"}},{"cell_type":"code","source":["def build_event_level_features(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    train_df나 test_episode_df에 공통 적용할 Event-level Feature Engineering 파이프라인\n","    \"\"\"\n","    df_fe = df.copy()\n","    # df_fe = sort_events(df_fe)\n","    df_fe = add_categorical_features(df_fe)\n","    df_fe = add_turnover_flag(df_fe)\n","    df_fe = add_movement_features(df_fe)\n","    df_fe = add_episode_cumulative_movement(df_fe)\n","\n","    return df_fe"],"metadata":{"id":"52U0CLh-yT35"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 8.3 에피소드별 Feature Engineering"],"metadata":{"id":"8F9ruFF_ym9u"}},{"cell_type":"markdown","source":["### 8.3.1 각도 변화량 요약 함수"],"metadata":{"id":"H5ByjDn8yruM"}},{"cell_type":"code","source":["def angle_diff(a1, a2):\n","    diff = a2 - a1\n","    diff = (diff + np.pi) % (2 * np.pi) - np.pi\n","    return diff\n","\n","def compute_angle_smoothness(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    episode별 angle 변화량 요약 (std, mean_abs, max 등)\n","    \"\"\"\n","    df = df.copy()\n","    # df = sort_events(df)\n","\n","    records = []\n","\n","    for ge, g in df.groupby(\"game_episode\"):\n","        ang = g[\"angle\"].values\n","        if len(ang) < 3:\n","            continue\n","\n","        diffs = [angle_diff(ang[i], ang[i+1]) for i in range(len(ang) - 1)]\n","\n","        records.append({\n","            \"game_episode\": ge,\n","            \"angle_change_std\": np.std(diffs),\n","            \"angle_change_mean_abs\": np.mean(np.abs(diffs)),\n","            \"angle_change_max\": np.max(np.abs(diffs)),\n","            \"angle_change_N\": len(diffs),\n","        })\n","\n","    angle_df = pd.DataFrame(records)\n","    return angle_df\n","\n","def add_angle_smoothness_to_epi(epi_feat: pd.DataFrame,\n","                                angle_smooth_df: pd.DataFrame) -> pd.DataFrame:\n","\n","    res = epi_feat.merge(angle_smooth_df, on=\"game_episode\", how=\"left\")\n","    # 결측은 0 또는 평균값으로 채워도 됨 (길이가 짧은 에피소드)\n","    res[[\"angle_change_std\", \"angle_change_mean_abs\",\n","         \"angle_change_max\", \"angle_change_N\"]] = \\\n","        res[[\"angle_change_std\", \"angle_change_mean_abs\",\n","             \"angle_change_max\", \"angle_change_N\"]].fillna(0.0)\n","\n","    return res"],"metadata":{"id":"rId_Lb7pyaxO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 8.3.2 episode별 요약 함수"],"metadata":{"id":"PJvIXbagy1cr"}},{"cell_type":"code","source":["def extract_episode_summary(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    episode별 요약 feature (len, ratio_pass/carry, dx/dy, dist 등)\n","    \"\"\"\n","    df = df.copy()\n","    # df = sort_events(df)\n","\n","    feats = []\n","\n","    for ge, g in df.groupby(\"game_episode\"):\n","        event_s = g[\"event_simple\"].values\n","\n","        xs = g[\"start_x\"].values\n","        ys = g[\"start_y\"].values\n","\n","        dx = np.diff(xs)\n","        dy = np.diff(ys)\n","        dist = np.sqrt(dx*dx + dy*dy)\n","        angle = np.arctan2(dy, dx)\n","\n","        len_epi = len(g)\n","\n","        feats.append({\n","            \"game_episode\": ge,\n","            \"epi_len\": len_epi,\n","\n","            # 단순화 버전 적용해서\n","            \"ratio_pass\": np.mean(event_s == \"Pass\"),\n","            \"ratio_carry\": np.mean(event_s == \"Carry\"),\n","            \"ratio_turnover\": np.mean(g[\"is_turnover\"].values),\n","\n","            \"dx_mean\": dx.mean() if len(dx) else 0,\n","            \"dy_mean\": dy.mean() if len(dy) else 0,\n","            \"angle_mean\": angle.mean() if len(angle) else 0,\n","            \"angle_std\": angle.std() if len(angle) else 0,\n","\n","            \"dist_mean\": dist.mean() if len(dist) else 0,\n","            \"dist_cum\": dist.sum() if len(dist) else 0,\n","\n","            \"start_zone_x\": get_zone_x(xs[0]),\n","            \"start_zone_y\": get_zone_y(ys[0]),\n","        })\n","\n","    return pd.DataFrame(feats)"],"metadata":{"id":"KR0tHHYWy4a9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 8.3.3 episode별 event entropy 추가 함수"],"metadata":{"id":"fuYdzWjBzQhU"}},{"cell_type":"code","source":["def add_episode_entropy(df: pd.DataFrame, epi_feat: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    episode별 event_simplified entropy 계산 후 epi_feat에 merge\n","    \"\"\"\n","    df = df.copy()\n","    # df = sort_events(df)\n","\n","    entropy_records = []\n","    for ge, g in df.groupby(\"game_episode\"):\n","        seq = g[\"event_simple\"].tolist()\n","        ent = sequence_entropy(seq)\n","        entropy_records.append({\"game_episode\": ge, \"entropy_event\": ent})\n","\n","    ent_df = pd.DataFrame(entropy_records)\n","\n","    epi_feat = epi_feat.merge(ent_df, on=\"game_episode\", how=\"left\")\n","    return epi_feat"],"metadata":{"id":"zs0QT95azTu-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 8.3.4 Episode summary 통합 최종 함수"],"metadata":{"id":"-jguJq9ZzjBM"}},{"cell_type":"code","source":["def build_episode_level_features(df_fe: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    Event별 FE가 적용된 df_fe를 입력 받아,\n","    episode별 summary feature를 생성.\n","    \"\"\"\n","    epi_feat = extract_episode_summary(df_fe)\n","    angle_smooth_df = compute_angle_smoothness(df_fe)\n","    epi_feat = add_angle_smoothness_to_epi(epi_feat, angle_smooth_df)\n","    epi_feat = add_episode_entropy(df_fe, epi_feat)\n","\n","    return epi_feat"],"metadata":{"id":"owLL4Lv8zlEl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","    일단 Baseline 모델에는\n","    Event-level에서 event_simple (embedding), result_simple (embedding), is_turnover, dx, dy, distance,\n","    angle, dt, zone_x/y (embedding), step_idx_norm, time_rel, cum_dx, cum_dy, movement_norm을 Input으로 넣고,\n","\n","    Episode-level에서는 epi_len, ratio_pass, ratio_carry, ratio_turnover, dx_mean, dy_mean,\n","    angle_mean, angle_std, dist_cum, dist_mean, angle_smoothness metrics, entropy_event을 Input으로 넣을 듯 !\n"],"metadata":{"id":"oxhQPLZQ4HTS"}},{"cell_type":"markdown","source":["# 9. 실제 Feature Engineering"],"metadata":{"id":"T2JgjWD05aJC"}},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv('Data/train.csv')"],"metadata":{"id":"qFHbPz7c5edz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_fe = build_event_level_features(df)\n","df_fe.head()"],"metadata":{"id":"EKs2ZxGFz8tG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_fe.info()"],"metadata":{"id":"0sTMCB7h6pri"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 356721 entries, 0 to 356720\n","Data columns (total 34 columns):\n"," #   Column         Non-Null Count   Dtype  \n","---  ------         --------------   -----  \n"," 0   game_id        356721 non-null  int64  \n"," 1   period_id      356721 non-null  int64  \n"," 2   episode_id     356721 non-null  int64  \n"," 3   time_seconds   356721 non-null  float64\n"," 4   team_id        356721 non-null  int64  \n"," 5   player_id      356721 non-null  int64  \n"," 6   action_id      356721 non-null  int64  \n"," 7   type_name      356721 non-null  object\n"," 8   result_name    216467 non-null  object\n"," 9   start_x        356721 non-null  float64\n"," 10  start_y        356721 non-null  float64\n"," 11  end_x          356721 non-null  float64\n"," 12  end_y          356721 non-null  float64\n"," 13  is_home        356721 non-null  bool   \n"," 14  game_episode   356721 non-null  object\n"," 15  event_simple   356721 non-null  object\n"," 16  result_simple  356721 non-null  object\n"," 17  zone_x         356721 non-null  object\n"," 18  zone_y         356721 non-null  object\n"," 19  dist_to_goal   356721 non-null  float64\n"," 20  angle_to_goal  356721 non-null  float64\n"," 21  is_turnover    356721 non-null  int64  \n"," 22  dx             356721 non-null  float64\n"," 23  dy             356721 non-null  float64\n"," 24  distance       356721 non-null  float64\n"," 25  angle          356721 non-null  float64\n"," 26  dt             356721 non-null  float64\n"," 27  step_idx       356721 non-null  int64  \n"," 28  epi_len        356721 non-null  int64  \n"," 29  step_idx_norm  356721 non-null  float64\n"," 30  time_rel       356721 non-null  float64\n"," 31  cum_dx         356721 non-null  float64\n"," 32  cum_dy         356721 non-null  float64\n"," 33  movement_norm  356721 non-null  float64\n","dtypes: bool(1), float64(17), int64(9), object(7)\n","memory usage: 90.2+ MB\n","```\n","\n"],"metadata":{"id":"jb89ftNg6siD"}},{"cell_type":"code","source":["df_fe[['type_name', 'result_name', 'event_simple', 'result_simple']]"],"metadata":{"id":"2blRmL2q6Xsy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epi_fe = build_episode_level_features(df_fe)\n","epi_fe.head()"],"metadata":{"id":"za7QG0OC5ie2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epi_fe.info()"],"metadata":{"id":"b_EGa6XJ7FEO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 15435 entries, 0 to 15434\n","Data columns (total 18 columns):\n"," #   Column                 Non-Null Count  Dtype  \n","---  ------                 --------------  -----  \n"," 0   game_episode           15435 non-null  object\n"," 1   epi_len                15435 non-null  int64  \n"," 2   ratio_pass             15435 non-null  float64\n"," 3   ratio_carry            15435 non-null  float64\n"," 4   ratio_turnover         15435 non-null  float64\n"," 5   dx_mean                15435 non-null  float64\n"," 6   dy_mean                15435 non-null  float64\n"," 7   angle_mean             15435 non-null  float64\n"," 8   angle_std              15435 non-null  float64\n"," 9   dist_mean              15435 non-null  float64\n"," 10  dist_cum               15435 non-null  float64\n"," 11  start_zone_x           15435 non-null  object\n"," 12  start_zone_y           15435 non-null  object\n"," 13  angle_change_std       15435 non-null  float64\n"," 14  angle_change_mean_abs  15435 non-null  float64\n"," 15  angle_change_max       15435 non-null  float64\n"," 16  angle_change_N         15435 non-null  float64\n"," 17  entropy_event          15435 non-null  float64\n","dtypes: float64(14), int64(1), object(3)\n","memory usage: 2.1+ MB\n","```\n","\n"],"metadata":{"id":"wWFFtweA7RSf"}},{"cell_type":"code","source":["epi_fe.describe().T.round(2)"],"metadata":{"id":"i2ph1hm77PyM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 10. 모델링"],"metadata":{"id":"trOzMMR88UuQ"}},{"cell_type":"markdown","source":["## 10.1 train/valid split"],"metadata":{"id":"X9aRKGEi8W91"}},{"cell_type":"markdown","source":["---\n","\n","    에피소드 단위로 split해야겠다 !\n","\n","    시퀀스 모델은 episode 전체를 하나의 샘플로 보고 학습하기 때문에 episode를 반으로 쪼개거나 섞으면 temporal dependency가 깨짐\n","\n","    같은 game_id 안에서 train/valid가 섞이면 데이터 누수 발생\n","    따라서 game_id 단위로 묶어서 episode 단위 split하는 게 가장 안전\n","\n","    그 중에서도 Game별로 Split 해야할 것 같은데,\n","    train 게임과 valid 게임을 완전히 분리하고, 하나의 game_id에 속한 모든 episode는 train 또는 valid 중 하나에만 배정하기\n","\n","    데이터 누수 0이고, 가장 현실적이라고 판단되기 때문에 이 기법으로 선택"],"metadata":{"id":"eFWSOk1W8aXw"}},{"cell_type":"code","source":["# 나누기 전에 tail 검증부터 (모두 최종 패스가 나와야 함)\n","orig_tail = df.groupby(\"game_episode\").tail(1)\n","\n","orig_tail_types = orig_tail[\"type_name\"].unique()\n","print(orig_tail_types)"],"metadata":{"id":"ZUqTKyXHBqQl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","['Pass']\n","```\n","\n"],"metadata":{"id":"dPQlzcvcB6Gu"}},{"cell_type":"code","source":["fe_tail = df_fe.groupby(\"game_episode\").tail(1)\n","fe_tail_types = fe_tail[\"type_name\"].unique()\n","\n","print(fe_tail_types)"],"metadata":{"id":"UrNnxgls7YID"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","['Pass' 'Carry']가 나온 걸 보아하니.. FE 과정에서 문제가 생긴 것 같아 뜯어고쳐봐야겠다\n","\n","⭐ 재정렬을 시키면 안 됐었다 !! 정렬 함수 삭제하니 ['Pass']만 나온다.\n","```\n","\n"],"metadata":{"id":"B0sYQxcSB9uj"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","'''\n","게임 단위 split (데이터 누수 방지)\n","'''\n","game_ids = df[\"game_id\"].unique()\n","\n","train_games, valid_games = train_test_split(\n","    game_ids,\n","    test_size=0.2,\n","    random_state=42,\n",")\n","\n","'''\n","에피소드 단위 split 기준 만들기 (split 기준은 반드시 원본 df에서 뽑기)\n","'''\n","train_epis = df[df[\"game_id\"].isin(train_games)][\"game_episode\"].unique()\n","valid_epis = df[df[\"game_id\"].isin(valid_games)][\"game_episode\"].unique()\n","\n","print(f\"Train games: {len(train_games)}, Valid games: {len(valid_games)}\")\n","print(f\"Train episodes: {len(train_epis)}, Valid episodes: {len(valid_epis)}\")\n","\n","'''\n","FE 이후 df_fe에서 에피소드 기준으로 데이터 분리\n","'''\n","train_df = df_fe[df_fe[\"game_episode\"].isin(train_epis)].copy()\n","valid_df = df_fe[df_fe[\"game_episode\"].isin(valid_epis)].copy()\n","\n","'''\n","Episode tail 검증\n","'''\n","train_tail_types = train_df.groupby(\"game_episode\").tail(1)[\"type_name\"].unique()\n","valid_tail_types = valid_df.groupby(\"game_episode\").tail(1)[\"type_name\"].unique()\n","\n","print(\"Train tail types:\", train_tail_types)\n","print(\"Valid tail types:\", valid_tail_types)\n","\n","assert set(train_tail_types) == {\"Pass\"}\n","assert set(valid_tail_types) == {\"Pass\"}\n","\n","print(\"Split integrity confirmed: all episode tails are Pass.\")"],"metadata":{"id":"NdJNpFyOAuaf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","Train games: 158, Valid games: 40\n","Train episodes: 12389, Valid episodes: 3046\n","Train tail types: ['Pass']\n","Valid tail types: ['Pass']\n","Split integrity confirmed: all episode tails are Pass.\n","```\n","\n"],"metadata":{"id":"2FqRfHj_Ef4C"}},{"cell_type":"code","source":["print(len(train_epis), len(valid_epis))\n","print(train_df.shape, valid_df.shape)"],"metadata":{"id":"PUx26aZD_wCP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["    12389 3046\n","    (285011, 34) (71710, 34)"],"metadata":{"id":"hmX-gVQA_3EI"}},{"cell_type":"markdown","source":["## 10.2 모델 입력 구조 설계"],"metadata":{"id":"mJSdAx2LFgoI"}},{"cell_type":"markdown","source":["---\n","\n","    FE(df_fe)는 “이벤트 1개 = 1 row” 형태고, 모델은 “episode 전체 = 1 sample(sequence)” 형태를 원함\n","\n","    최종적으로 각 episode는 다음과 같은 tensor로 구성\n","    - X_seq: 이벤트 시퀀스 feature (T × F)\n","    - mask: padding mask (T)\n","    - target_x, target_y: 에피소드 마지막 패스 end_x, end_y\n","    - (선택) categorical embedding index들\n","    - (선택) episode별 feature\n","\n","    일단 baseline은 event-level numeric features만 들어가는 baseline version으로 구성하고,\n","    categorical embedding은 이후 단계에서 추가해볼 버전에 넣어보든가 하기"],"metadata":{"id":"Qu24BRDgFiC5"}},{"cell_type":"markdown","source":["    Baseline Input Features\n","\n","| Feature        | 의미                   |\n","| -------------- | -------------------- |\n","| dx, dy         | 이동량                  |\n","| distance       | 이동 거리                |\n","| angle          | 이동 방향                |\n","| dt             | 이벤트 간 시간차            |\n","| step_idx_norm  | 시퀀스 내 포지션            |\n","| time_rel       | 상대 시간                |\n","| cum_dx, cum_dy | 에피소드 누적 이동량          |\n","| movement_norm  | 누적 이동량 크기            |\n","| dist_to_goal   | 골대까지 거리              |\n","| angle_to_goal  | 골대 방향 각도             |\n","| is_turnover    | 1-step turnover flag |"],"metadata":{"id":"utkMF4T9IZ33"}},{"cell_type":"markdown","source":["### 10.2.1 입력 구조 설계 함수 정의"],"metadata":{"id":"ythJiZdAI40S"}},{"cell_type":"code","source":["def build_episode_sequences(df):\n","    \"\"\"\n","    df_fe를 episode 단위로 list로 묶어주는 함수.\n","    output: {game_episode: df_subset}\n","    \"\"\"\n","    episodes = {}\n","\n","    for ge, g in df.groupby(\"game_episode\"):\n","        g_sorted = g.sort_values([\"time_seconds\", \"action_id\"])\n","        episodes[ge] = g_sorted.reset_index(drop=True)\n","\n","    return episodes\n","\n","def extract_targets(episodes):\n","    targets = {}\n","\n","    for ge, g in episodes.items():\n","        last = g.iloc[-1]\n","        targets[ge] = (last[\"end_x\"], last[\"end_y\"])\n","\n","    return targets\n","\n","NUMERIC_FEATURES = [\n","    \"dx\", \"dy\", \"distance\", \"angle\",\n","    \"dt\",\n","    \"step_idx_norm\", \"time_rel\",\n","    \"cum_dx\", \"cum_dy\", \"movement_norm\",\n","    \"dist_to_goal\", \"angle_to_goal\",\n","    \"is_turnover\"\n","]\n","\n","def episode_to_matrix(g, feature_cols=NUMERIC_FEATURES):\n","    \"\"\"\n","    episode subset df → (T, F) numpy matrix\n","    \"\"\"\n","    return g[feature_cols].values.astype(\"float32\")"],"metadata":{"id":"Lb4bQ01UAGii"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.2.2 Padding + Attention Mask 생성"],"metadata":{"id":"SFzjTY5eJhRx"}},{"cell_type":"code","source":["def pad_sequence(seq, max_len):\n","    \"\"\"\n","    seq: (T, F)\n","    return:\n","      padded_seq: (max_len, F)\n","      mask: (max_len,)  — 1: 실제 token, 0: padding\n","    \"\"\"\n","    T, F = seq.shape\n","    pad_len = max_len - T\n","\n","    # 길이가 짧을 때, 부족한 만큼 0으로 Zero-padding\n","    # 이때 mask를 만들어 어디까지가 진짜 데이터이고, 어디부터가 0인지 표시(1은 데이터, 0은 패딩)\n","    if pad_len > 0:\n","        pad = np.zeros((pad_len, F), dtype=\"float32\")\n","        padded = np.concatenate([seq, pad], axis=0)\n","        mask = np.concatenate([np.ones(T), np.zeros(pad_len)])\n","    # 길이가 길 때, max_len만큼만 자르기\n","    else:\n","        padded = seq[:max_len]\n","        mask = np.ones(max_len)\n","\n","    return padded, mask.astype(\"float32\")"],"metadata":{"id":"gknaS56_Jgu9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.2.3 PyTorch Dataset 설계"],"metadata":{"id":"758hDWN-Jyx3"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","\n","class EpisodeDataset(Dataset):\n","    '''\n","    PyTorch의 DataLoader가 데이터를 배치 단위로 뽑아갈 수 있도록 포장하는 클래스\n","    '''\n","    def __init__(self, episodes, targets, max_len=270, feature_cols=NUMERIC_FEATURES):\n","        self.episodes = episodes\n","        self.targets = targets\n","        self.keys = list(episodes.keys())\n","        self.max_len = max_len\n","        self.feature_cols = feature_cols\n","\n","    def __len__(self):\n","        return len(self.keys)\n","\n","    def __getitem__(self, idx):\n","        ge = self.keys[idx]     # idx번째 에피소드 데이터를 가져오고,\n","        g = self.episodes[ge]\n","\n","        # ---- build seq feature ----\n","        seq = episode_to_matrix(g, self.feature_cols)   # 데이터를 행렬로 바꾸고,\n","        seq_pad, mask = pad_sequence(seq, self.max_len) # 길이를 max_len으로 맞추고 마스크 생성하고,\n","\n","        # ---- target ----\n","        tx, ty = self.targets[ge]   # 정답 좌표 (x, y) 가져와서,\n","        target = np.array([tx, ty], dtype=\"float32\")\n","\n","        # Tensor 형태로 변환된 x(입력), mask(패딩 정보), target(정답) 딕셔너리 내보내기\n","        return {\n","            \"x\": torch.tensor(seq_pad),\n","            \"mask\": torch.tensor(mask),\n","            \"target\": torch.tensor(target),\n","        }"],"metadata":{"id":"GEA64CVeJolL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 10.3 train/valid Dataset 생성"],"metadata":{"id":"v1HLUYW8L4jI"}},{"cell_type":"code","source":["train_episodes = build_episode_sequences(train_df)\n","valid_episodes = build_episode_sequences(valid_df)\n","\n","train_targets = extract_targets(train_episodes)\n","valid_targets = extract_targets(valid_episodes)\n","\n","MAX_LEN = 270  # episode 최대 길이 기준\n","\n","train_dataset = EpisodeDataset(train_episodes, train_targets, max_len=MAX_LEN)\n","valid_dataset = EpisodeDataset(valid_episodes, valid_targets, max_len=MAX_LEN)"],"metadata":{"id":"SXevwI_oJ53O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 10.4 1차 베이스라인"],"metadata":{"id":"A4oKvySsOjqs"}},{"cell_type":"markdown","source":["---\n","\n","    RNN 계열은 시퀀스 데이터 처리의 기본 골격 / 기존 연구들에서도 경기 이벤트, 스포츠 시계열 데이터에 LSTM / BiLSTM 사용 사례 많음\n","\n","    특히 양방향 BiLSTM은 앞뒤 문맥 모두 고려 가능, 빌드업 전체 흐름을 학습하기에 적합. 실제로 최근 축구 이벤트 기반 분석에서도 활용된 사례 존재\n","\n","[활용 사례](https://www.mdpi.com/2079-9292/13/20/4105?utm_source=chatgpt.com)\n","\n","    Transformer나 복잡한 구조는 이후 확장 후보로 두고, 먼저 “단순 + 안정 + 빠른 실험”을 위해 BiLSTM이 이상적"],"metadata":{"id":"mhv1ymF2Pgp8"}},{"cell_type":"code","source":["# 사용할 Feature 정의\n","CONT_COLS = [\n","    \"dx\", \"dy\",\n","    \"distance\",\n","    \"angle\",\n","    \"dt\",\n","    \"step_idx_norm\",\n","    \"time_rel\",\n","    \"cum_dx\", \"cum_dy\",\n","    \"movement_norm\",\n","    \"dist_to_goal\",\n","    \"angle_to_goal\",\n","    \"is_turnover\"\n","]\n","\n","CAT_COLS = [\n","    \"event_simple\",\n","    \"result_simple\",\n","    \"zone_x\",\n","    \"zone_y\",\n","    \"is_home\"\n","]"],"metadata":{"id":"Pf6XyX4BRqyu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["    test.csv에서도 동일한 encoder를 사용해야 하므로, encoders는 pickle로 저장해두고 inference에서 다시 load해야 함"],"metadata":{"id":"WJ9V80bbR3Nv"}},{"cell_type":"markdown","source":["### 10.4.1 인코더 설계"],"metadata":{"id":"BpBo2LnISYHa"}},{"cell_type":"code","source":["def build_label_encoders(df):\n","    encoders = {}\n","    num_classes = {}\n","\n","    for col in CAT_COLS:\n","        uniques = sorted(df[col].dropna().unique())\n","        encoders[col] = {u: i for i, u in enumerate(uniques)}\n","        num_classes[col] = len(uniques)\n","\n","    return encoders, num_classes\n","\n","encoders, num_classes_dict = build_label_encoders(df_fe)"],"metadata":{"id":"_KoGF8y-RwyL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","with open(\"encoders.pkl\", \"wb\") as f:\n","    pickle.dump(encoders, f)\n","\n","with open(\"num_classes.pkl\", \"wb\") as f:\n","    pickle.dump(num_classes_dict, f)"],"metadata":{"id":"vsqjl8ByR2Vy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.4.2 Dataset & Collate 설계"],"metadata":{"id":"cwheClg5Sai1"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","\n","class EpisodeDataset(Dataset):\n","    def __init__(self, df, episode_ids, cont_cols, cat_cols, encoders, target_cols=(\"end_x\",\"end_y\")):\n","        self.cont_cols = cont_cols\n","        self.cat_cols = cat_cols\n","        self.encoders = encoders\n","        self.target_cols = target_cols\n","\n","        self.episodes = []\n","        sub = df[df[\"game_episode\"].isin(episode_ids)]\n","\n","        for ge, g in sub.groupby(\"game_episode\"):\n","            g = g.sort_values([\"time_seconds\", \"action_id\"]).reset_index(drop=True)\n","\n","            # numeric\n","            x_cont = torch.tensor(g[cont_cols].values, dtype=torch.float32)\n","\n","            # categorical label encoding\n","            cat_encoded = []\n","            for col in cat_cols:\n","                cat_encoded.append(g[col].map(encoders[col]).fillna(0).astype(int))\n","            x_cat = torch.tensor(np.vstack(cat_encoded).T, dtype=torch.long)\n","\n","            y = torch.tensor(g[target_cols].iloc[-1].values, dtype=torch.float32)\n","\n","            self.episodes.append((x_cont, x_cat, y))\n","\n","    def __len__(self):\n","        return len(self.episodes)\n","\n","    def __getitem__(self, idx):\n","        return self.episodes[idx]\n","\n","\n","def collate_fn(batch):\n","    x_cont_list, x_cat_list, y_list = zip(*batch)\n","\n","    lengths = torch.tensor([len(x) for x in x_cont_list], dtype=torch.long)\n","\n","    x_cont_padded = pad_sequence(x_cont_list, batch_first=True)\n","    x_cat_padded  = pad_sequence(x_cat_list, batch_first=True)\n","\n","    y = torch.stack(y_list)\n","\n","    return x_cont_padded, x_cat_padded, lengths, y"],"metadata":{"id":"K1wHR7OqSKy8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.4.3 모델 설계(BiLSTM)"],"metadata":{"id":"DGTrzcE0ScfT"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.nn.utils.rnn import pack_padded_sequence\n","\n","class BiLSTMFinalPassRegressor(nn.Module):\n","    def __init__(self, num_classes_dict, cont_dim, lstm_hidden=128, lstm_layers=1, dropout=0.2):\n","        super().__init__()\n","\n","        self.cat_cols = list(num_classes_dict.keys())\n","\n","        self.emb_layers = nn.ModuleDict({\n","            col: nn.Embedding(n, min(16, (n+1)//2))\n","            for col, n in num_classes_dict.items()\n","        })\n","\n","        emb_dim = sum([min(16, (n+1)//2) for n in num_classes_dict.values()])\n","        self.input_dim = cont_dim + emb_dim\n","\n","        self.lstm = nn.LSTM(\n","            input_size=self.input_dim,\n","            hidden_size=lstm_hidden,\n","            num_layers=lstm_layers,\n","            batch_first=True,\n","            bidirectional=True,\n","        )\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(lstm_hidden * 2, 128),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(128, 2)  # end_x, end_y\n","        )\n","\n","\n","    def forward(self, x_cont, x_cat, lengths):\n","        emb_list = []\n","        for i, col in enumerate(self.cat_cols):\n","            emb_list.append(self.emb_layers[col](x_cat[:, :, i]))\n","\n","        x_emb = torch.cat(emb_list, dim=-1)\n","        x = torch.cat([x_cont, x_emb], dim=-1)\n","\n","        lengths_sorted, sort_idx = lengths.sort(descending=True)\n","        x_sorted = x[sort_idx]\n","\n","        packed = pack_padded_sequence(x_sorted, lengths_sorted.cpu(), batch_first=True)\n","        _, (h_n, _) = self.lstm(packed)\n","\n","        h_forward = h_n[-2]\n","        h_backward = h_n[-1]\n","        h = torch.cat([h_forward, h_backward], dim=-1)\n","\n","        _, inv_idx = sort_idx.sort()\n","        h = h[inv_idx]\n","\n","        return self.fc(h)"],"metadata":{"id":"1Jk-FffOR8qV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 10.5 train.py 구조"],"metadata":{"id":"46cuTapBS2Ms"}},{"cell_type":"code","source":["# train.py\n","import torch\n","from torch.utils.data import DataLoader\n","import pandas as pd\n","import pickle\n","\n","from dataset import EpisodeDataset, collate_fn\n","from model import BiLSTMFinalPassRegressor\n","\n","# ----------------------\n","# 1. 데이터 로드\n","# ----------------------\n","df = pd.read_csv(\"train.csv\")\n","\n"," = pd.read_csv(\"train_fe.csv\")  # FE 후 저장한 파일\n","\n","with open(\"encoders.pkl\", \"rb\") as f:\n","    encoders = pickle.load(f)\n","with open(\"num_classes.pkl\", \"rb\") as f:\n","    num_classes_dict = pickle.load(f)\n","\n","# ----------------------\n","# 2. Dataset / Loader\n","# ----------------------\n","train_dataset = EpisodeDataset(df_fe, train_episode_ids, CONT_COLS, CAT_COLS, encoders)\n","valid_dataset = EpisodeDataset(df_fe, valid_episode_ids, CONT_COLS, CAT_COLS, encoders)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n","valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n","\n","# ----------------------\n","# 3. 모델 / 학습 Loop\n","# ----------------------\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model = BiLSTMFinalPassRegressor(num_classes_dict, len(CONT_COLS)).to(device)\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n","criterion = torch.nn.MSELoss()\n","\n","for epoch in range(10):\n","    model.train()\n","    total = 0\n","    for x_cont, x_cat, lengths, y in train_loader:\n","        x_cont, x_cat, lengths, y = x_cont.to(device), x_cat.to(device), lengths.to(device), y.to(device)\n","\n","        pred = model(x_cont, x_cat, lengths)\n","        loss = criterion(pred, y)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total += loss.item()\n","\n","    print(f\"Epoch {epoch} Train Loss = {total:.4f}\")\n","\n","torch.save(model.state_dict(), \"model.pt\")"],"metadata":{"id":"jnTqtVr-SSrB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 10.6 inference.py"],"metadata":{"id":"IOoasUP1TBT7"}},{"cell_type":"code","source":["# inference.py\n","import torch\n","import pandas as pd\n","import numpy as np\n","import pickle\n","\n","from dataset import EpisodeDataset, collate_fn\n","from model import BiLSTMFinalPassRegressor\n","from torch.utils.data import DataLoader\n","\n","# ----------------------\n","# 1. Load FE Test Data\n","# ----------------------\n","df_test = pd.read_csv(\"test_fe.csv\")\n","\n","with open(\"encoders.pkl\", \"rb\") as f:\n","    encoders = pickle.load(f)\n","with open(\"num_classes.pkl\", \"rb\") as f:\n","    num_classes_dict = pickle.load(f)\n","\n","episode_ids = df_test[\"game_episode\"].unique()\n","\n","test_dataset = EpisodeDataset(df_test, episode_ids, CONT_COLS, CAT_COLS, encoders)\n","test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n","\n","# ----------------------\n","# 2. Load Model\n","# ----------------------\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model = BiLSTMFinalPassRegressor(num_classes_dict, len(CONT_COLS))\n","model.load_state_dict(torch.load(\"model.pt\", map_location=device))\n","model.to(device)\n","model.eval()\n","\n","# ----------------------\n","# 3. Prediction\n","# ----------------------\n","preds = []\n","\n","with torch.no_grad():\n","    for x_cont, x_cat, lengths, y in test_loader:\n","        x_cont, x_cat, lengths = x_cont.to(device), x_cat.to(device), lengths.to(device)\n","\n","        out = model(x_cont, x_cat, lengths)\n","        out = out.cpu().numpy()[0]\n","\n","        preds.append(out)\n","\n","preds = np.array(preds)\n","\n","# ----------------------\n","# 4. Make Submission\n","# ----------------------\n","sample = pd.read_csv(\"sample_submission.csv\")\n","\n","sample[\"end_x\"] = preds[:, 0]\n","sample[\"end_y\"] = preds[:, 1]\n","\n","sample.to_csv(\"submission.csv\", index=False)\n","print(\"Saved submission.csv\")"],"metadata":{"id":"SiKUrwoBTDzn"},"execution_count":null,"outputs":[]}]}